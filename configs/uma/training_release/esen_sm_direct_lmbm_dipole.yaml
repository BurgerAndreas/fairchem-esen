defaults:
  - cluster: one
  - backbone: K4L2
  - dataset: custom_lmdb # custom_xyz
  - tasks: custom_energy_dipole
  - _self_
  - lrs: cosine
  - batching: maxatoms # maxatoms or regular

# Mace uses 
# hidden_irreps: 128x0e + 128x1o # + 128x2e 
backbone:
  max_num_elements: 17
  # need max + 1 because of 0-indexing 
  # H, C, O, N, F=9 S=16
  sphere_channels: 128
  lmax: 1
  mmax: 1 # from -lmax to lmax
  # Disable PBC for molecules
  use_pbc: False
  use_pbc_single: False
  always_use_pbc: False

# Data path for cluster
dataset:
  data_path: /project/aip-aspuru/aburger/fairchem-esen/data/dipole/ # Killarney 

job:
  device_type: ${cluster.device}
  scheduler:
    mode: ${cluster.mode}
    ranks_per_node: ${cluster.ranks_per_node}
    num_nodes: 1
    slurm:
      account: ${cluster.account}
      qos: ${cluster.qos}
      mem_gb: ${cluster.mem_gb}
      cpus_per_task: ${cluster.cpus_per_task}
  debug: ${cluster.debug}
  run_dir: ${cluster.run_dir}
  logs_dir: /scratch/aburger/esen_logs
  run_name: uma_sm_direct_customdata
  logger:
    _target_: fairchem.core.common.logger.WandBSingletonLogger.init_wandb
    _partial_: true
    entity: andreas-burger
    project: uma_custom
    wandb_dir: /scratch/aburger/wandb

moe_layer_type: pytorch
num_moe_experts: 0
max_neighbors: 30
cutoff_radius: 6
bf16: True
# cpu_graph: True
otf_graph: False
# normalizer_rmsd: 1.0
# direct_forces_coef: 10

regress_stress: False
direct_forces: False

dataset_list: ["custom"]

exclude_keys: []

train_dataset:
  _target_: fairchem.core.datasets.mt_concat_dataset.create_concat_dataset
  dataset_configs:
    custom: ${dataset.custom_train}
  combined_dataset_config:
    sampling:
      type: explicit
      ratios:
        custom.train: 1.0

val_dataset:
  _target_: fairchem.core.datasets.mt_concat_dataset.create_concat_dataset
  dataset_configs:
    custom: ${dataset.custom_val}
  combined_dataset_config: { sampling: {type: temperature, temperature: 1.0} }

train_dataloader:
  _target_: fairchem.core.components.common.dataloader_builder.get_dataloader
  dataset: ${train_dataset}
  batch_sampler_fn:
    _partial_: True
    shuffle: True
    seed: 0
  num_workers: ${cluster.dataloader_workers}
  collate_fn:
    _target_: fairchem.core.units.mlip_unit.mlip_unit.mt_collater_adapter
    tasks: ${tasks}
    exclude_keys: ${exclude_keys}

eval_dataloader:
  _target_: fairchem.core.components.common.dataloader_builder.get_dataloader
  dataset: ${val_dataset}
  batch_sampler_fn:
    _partial_: True
    shuffle: False
    seed: 0
  num_workers: ${cluster.dataloader_workers}
  collate_fn:
    _target_: fairchem.core.units.mlip_unit.mlip_unit.mt_collater_adapter
    tasks: ${tasks}
    exclude_keys: ${exclude_keys}

heads:
  energy:
    module: fairchem.core.models.uma.escn_md.MLP_Energy_Head
  dipole:
    module: fairchem.core.models.uma.escn_md.Linear_Dipole_Head
  # forces:
  #   module: fairchem.core.models.uma.escn_md.Linear_Force_Head

runner:
  _target_: fairchem.core.components.train.train_runner.TrainEvalRunner
  train_dataloader: ${train_dataloader}
  eval_dataloader: ${eval_dataloader}
  train_eval_unit:
    _target_: fairchem.core.units.mlip_unit.mlip_unit.MLIPTrainEvalUnit
    job_config: ${job}
    tasks: ${tasks}
    model:
      _target_: fairchem.core.models.base.HydraModel
      backbone: ${backbone}
      heads: ${heads}
    optimizer_fn:
      _target_: torch.optim.AdamW
      _partial_: true
      lr: 5e-4
      weight_decay: 1e-3
    print_every: 100
    clip_grad_norm: 100
    bf16: ${bf16}
  max_epochs: 1000
  max_steps: null # 50000
  evaluate_every_n_steps: null
  evaluate_every_n_epochs: 5
  callbacks:
    - _target_: fairchem.core.common.profiler_utils.ProfilerCallback
      job_config: ${job}
    - _target_: fairchem.core.components.train.train_runner.TrainCheckpointCallback
      checkpoint_every_n_steps: 2000
      max_saved_checkpoints: 3

