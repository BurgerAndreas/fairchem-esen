# @package _global_

runner:
  train_eval_unit:
    lr_scheduler_fn:
      _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
      _partial_: true
      mode: min # based on validation loss
      # Factor by which the learning rate will be
      #     reduced. new_lr = lr * factor. Default: 0.1.
      # patience (int): The number of allowed epochs with no improvement after
      #     which the learning rate will be reduced
      factor: 0.9
      patience: 10 # in epochs
      # Threshold for measuring the new optimum
      threshold: 1e-4
      threshold_mode: rel
      min_lr: 1e-6